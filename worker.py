import logging
import os
import socket
import traceback
import warnings
from builtins import object, str
from typing import Dict, Union, Any

from utilities import ensure_directory

# shhh
warnings.filterwarnings('ignore')

# for garrays
os.environ['GNUMPY_IMPLICIT_CONVERSION'] = 'allow'

# load the library-wide logger
LOGGER = logging.getLogger('mlb')

# Local hostname, for logging.
HOSTNAME = socket.gethostname()


# Exception thrown when something goes wrong for the worker, but the worker handles the error.
class ClassifierError(Exception):
    pass


class Worker(object):
    def __init__(self, database, dataset, save_files=True, cloud_mode=False,
                 aws_access_key=None, aws_secret_key=None, s3_bucket=None, s3_folder=None,
                 models_dir='models', metrics_dir='metrics', verbose_metrics=False):

        self.db = database
        self.dataset = dataset
        self.save_files = save_files
        self.cloud_mode = cloud_mode

        self.aws_access_key = aws_access_key
        self.aws_secret_key = aws_secret_key
        self.s3_bucket = s3_bucket
        self.s3_folder = s3_folder

        self.models_dir = models_dir
        self.metrics_dir = metrics_dir
        self.verbose_metrics = verbose_metrics
        ensure_directory(self.models_dir)
        ensure_directory(self.metrics_dir)

        # load the Dataset from the database
        self.dataset = self.db.get_dataset(self.dataset.dataset_id)

    def transform_dataset(self, algorithm: str, params: Dict) -> Union[str, Any]:
        """
        Given a set of fully-qualified hyperparameters, create and test a
        classifier model.
        Returns: Model object and metrics dictionary
        """

        train_path, test_path = self.dataset.load()

        # TODO Create algorithm instance from algorithm + params
        # If classifier:
        #   - Cross-Validation to fit model
        #   - Calculate averaged metrics
        # If transformer:
        #   - Transform dataset
        #   - Store transformed dataset in tmp directory

        return ''

    def save_classifier(self, classifier_id: int, res: Union[str, Any]) -> None:
        """
        Update a classifier with metrics and model information and mark it as
        "complete"

        classifier_id: ID of the classifier to save

        model: Model object containing a serializable representation of the
            final model generated by this classifier.

        metrics: Dictionary containing cross-validation and test metrics data
            for the model.
        """

        # TODO store algorithm with either metrics or new transformed dataset in database
        if isinstance(res, str):
            # TODO add new dataset
            pass
        else:
            # TODO store metrics

            # update the classifier in the database
            self.db.complete_classifier(classifier_id=classifier_id)

        LOGGER.info('Saved classifier %d.' % classifier_id)

    def is_dataset_finished(self):
        classifiers = self.db.get_classifiers(dataset_id=self.dataset.id)
        if not classifiers:
            LOGGER.warning('No incomplete classifiers for dataset %d present in database.'
                           % self.dataset.id)
            return True

        n_completed = len(classifiers)
        if n_completed >= self.dataset.budget:
            LOGGER.warning('Classifier budget has run out!')
            return True

        return False

    def run_classifier(self):
        # check to see if our work is done
        if self.is_dataset_finished():
            # marked the run as done successfully
            self.db.mark_dataset_complete(self.dataset.id)
            LOGGER.warning('Dataset %d has ended.' % self.dataset.id)
            return

        try:
            LOGGER.debug('Choosing algorithm...')
            # TODO select random algorithm
            algorithm = ''
            # TODO select random hyperparameters
            params = {}

        except Exception:
            LOGGER.error('Error choosing hyperparameters: datarun=%s' % str(self.dataset))
            LOGGER.error(traceback.format_exc())
            raise ClassifierError()

        param_info = 'Chose parameters for algorithm "%s":' % algorithm
        for k in sorted(params.keys()):
            param_info += '\n\t%s = %s' % (k, params[k])
        LOGGER.info(param_info)

        LOGGER.debug('Creating classifier...')
        classifier = self.db.start_classifier(datarun_id=self.dataset.id,
                                              host=HOSTNAME,
                                              algorithm=algorithm,
                                              hyperparameter_values=params)

        try:
            LOGGER.debug('Testing classifier...')
            res = self.transform_dataset(algorithm, params)

            LOGGER.debug('Saving classifier...')
            self.save_classifier(classifier.id, res)

        except Exception:
            msg = traceback.format_exc()
            LOGGER.error('Error testing classifier: datarun=%s' % str(self.dataset))
            LOGGER.error(msg)
            self.db.mark_classifier_errored(classifier.id, error_message=msg)
            raise ClassifierError()
