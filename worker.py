import logging
import random
import socket
import traceback
import warnings
from builtins import object, str
from datetime import datetime
from typing import Optional, Tuple, Dict
import numpy as np
import pandas as pd
from autosklearn.metrics import average_precision

from sklearn.base import BaseEstimator, is_classifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score
from sklearn.model_selection import train_test_split

from constants import AlgorithmStatus
from data import load_data
from database import Database, Algorithm
from methods import ALGORITHMS
from utilities import ensure_directory

warnings.filterwarnings('ignore')

LOGGER = logging.getLogger('mlb')
HOSTNAME = socket.gethostname()


# Exception thrown when something goes wrong for the worker, but the worker handles the error.
class AlgorithmError(Exception):
    pass


class Worker(object):
    def __init__(self,
                 database: Database,
                 dataset,
                 cloud_mode: bool = False,
                 s3_access_key: str = None,
                 s3_secret_key: str = None,
                 s3_bucket: str = None,
                 models_dir: str = 'models',
                 metrics_dir: str = 'metrics',
                 verbose_metrics: bool = False):

        self.db = database
        self.dataset = dataset
        self.cloud_mode = cloud_mode

        self.s3_access_key = s3_access_key
        self.s3_secret_key = s3_secret_key
        self.s3_bucket = s3_bucket

        self.models_dir = models_dir
        self.metrics_dir = metrics_dir
        self.verbose_metrics = verbose_metrics
        ensure_directory(self.models_dir)
        ensure_directory(self.metrics_dir)

        """
        Load the Dataset from the database
        """
        self.dataset = self.db.get_dataset(self.dataset.id)

    def transform_dataset(self, algorithm: BaseEstimator) -> Tuple[pd.DataFrame, Dict[str, float]]:
        """
        Given a set of fully-qualified hyperparameters, create and test a
        algorithm model.
        Returns: Model object and metrics dictionary
        """

        train_path, test_path = self.dataset.load()

        df = load_data(train_path)
        X, y = df.drop('class', axis=1), df['class']

        # TODO Create algorithm instance from algorithm + params
        # If classifier:
        #   - Cross-Validation to fit model
        #   - Calculate averaged metrics
        # If transformer:
        #   - Transform dataset
        #   - Store transformed dataset in tmp directory

        """
        algorithm kann also auch ein zufälliger Transformationsalgorithmus sein? Ebenfalls aus dem methods-Ordner?
        
        Classifier ja oder nein?
        Wenn ja: Algorithmus auf Datenset anwenden und Score berechnen -> X, y Werte des Datensets dem Algorithmus
        übergeben und durch Score-Methode Accuracy berechnet (?)
        
        Sonst Transformer: Transformer auf Datenset anwenden und anschließend das neue Datenset als neues Datenset
        in tmp directory speichern.
        Wenn der Tranformer keine Veränderung am Datenset vorgenommen hat (Imputation aber Datenset hatte keine
        Missing Values) soll das Datenset den schlechtesten Accuracy Score bekommen und somit in save_algorithm nicht
        (als neues Datenset) gespeichert werden.
        
        Return: Zurückgegeben als res, wird dann entweder der auf dem Datenset gelaufene Algorithmus und der berechnete
        Score oder das transformierte Datenset. models_dir & metrics_dir
        """
        if is_classifier(algorithm):
            X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

            algorithm.fit(X_train, y_train)

            y_pred = algorithm.predict(X_test)

            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred)
            av_precision = average_precision(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            neg_log_loss = log_loss(y_test, y_pred)
            roc_auc = roc_auc_score(y_test, y_pred)

            return X, {'accuracy': accuracy,
                       'precision': precision,
                       'av_precision': av_precision,
                       'recall': recall,
                       'f1': f1,
                       'neg_log_loss': neg_log_loss,
                       'roc_auc': roc_auc
                       }
        else:
            X = algorithm.fit_transform(X, y)
            return X, {}

    def save_algorithm(self, algorithm_id: Optional[int], res: Tuple[pd.DataFrame, Dict[str, float]]) -> None:
        """
        Update a algorithm with metrics and model information and mark it as
        "complete"

        algorithm_id: ID of the algorithm to save

        model: Model object containing a serializable representation of the
            final model generated by this algorithm.

        metrics: Dictionary containing cross-validation and test metrics data
            for the model.
        """

        # TODO store algorithm with either metrics or new transformed dataset in database

        self.db.complete_algorithm(algorithm_id=algorithm_id, **res[1])

        # Add new dataset entry to db
        # store dataframe on disk with uuid name

        LOGGER.info('Saved algorithm {}.'.format(algorithm_id))

    """
    Check if dataset is finished
    
    First is_dataset_finished checks if there are algorithms for this dataset in the database marked as pending or
    started. If there are none it returns False.
    
    Then is_dataset_finished checks if a dataset has enough budget for all the algorithms in the list.
    If the dataset has run out of budget, is_data_set returns True.
    """
    def is_dataset_finished(self):
        algorithms = self.db.get_algorithms(dataset_id=self.dataset.id, ignore_complete=False)
        # No algorithms for this data set started yet
        if not algorithms:
            return False

        n_completed = len(algorithms)
        if n_completed >= self.dataset.budget:
            LOGGER.warning('Algorithm budget for dataset {} has run out!'.format(self.dataset))
            return True

        return False

    def run_algorithm(self):
        """
        Check to see if our work is done

        First run_algorithm checks if is_dataset_finished returns True or False. If it returns True, the dataset is
        marked as complete. If is_dataset_finished returns False, run_algorithm creates a new Algorithm instance with
        a random Algorithm method. A random set of parameter configurations then is created for the Algorithms
        hyperparameter and stored in the new Algorithm instance.

        With the start_algorithm method, the new Algorithm instance then is stored in the database.

        As a last step the methods run_algorithm calls the methods transform_dataset and save_algorithm.
        """
        if self.is_dataset_finished():
            """
            Mark the run as done successfully
            """
            self.db.mark_dataset_complete(self.dataset.id)
            LOGGER.warning('Dataset {} has been marked as complete.'.format(self.dataset))
            return

        """
        Choose a random algorithm to work on the dataset
        """
        try:
            LOGGER.debug('Choosing algorithm...')
            algorithm = Algorithm(random.choice(ALGORITHMS),
                                  dataset_id=self.dataset.id,
                                  hyperparameter_values=None,
                                  status=AlgorithmStatus.RUNNING,
                                  start_time=datetime.now())

            """Save a random configuration of the algorithms hyperparameters in params"""
            params = algorithm.random_config()
            algorithm.hyperparameter_values = params

        except Exception:
            LOGGER.error('Error choosing hyperparameters: dataset={}'.format(self.dataset))
            LOGGER.error(traceback.format_exc())
            raise AlgorithmError()

        param_info = 'Chose parameters for algorithm "{}":'.format(algorithm.class_path)
        for k in sorted(params.keys()):
            param_info += '\n\t{} = {}'.format(k, params[k])
        LOGGER.info(param_info)

        LOGGER.debug('Creating algorithm...')

        """
        Start the algorithm (add it to database)
        """
        algorithm = self.db.start_algorithm(dataset_id=self.dataset.id,
                                            host=HOSTNAME,
                                            algorithm=algorithm,
                                            start_time=algorithm.start_time,
                                            status=algorithm.status)

        """
        Transform the dataset and save the algorithm
        """
        try:
            LOGGER.debug('Testing algorithm...')
            res = self.transform_dataset(algorithm.instance(params))

            LOGGER.debug('Saving algorithm...')
            self.save_algorithm(algorithm.id, res)

        except Exception:
            msg = traceback.format_exc()
            LOGGER.error('Error testing algorithm: dataset={}'.format(self.dataset))
            LOGGER.error(msg)
            self.db.mark_algorithm_errored(algorithm.id, error_message=msg)
            raise AlgorithmError()
